{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abenojar, Jesrelle Anne\n",
    "\n",
    "Alvaro, Justine Paul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 180 MP 2\n",
    "## Sentiment Analysis of Online Reviews using Naive Bayes Algorithm\n",
    "\n",
    "## I.  Introduction\n",
    "\n",
    "Online reviews play a key role in the success of businesses in today’s digital age. According to a BrightLocal survey in 2014, 88% of consumers have read reviews to determine the quality of local businesses. Their findings reveal that these customers trust online reviews as much as personal recommendations. This shows the increasing trend of consumers’ use of online reviews. The group thought that automating the analysis of such reviews would be a big help to local businesses in assessing the quality of their service.\n",
    "\n",
    "## II.  Methodology\n",
    "\n",
    "The dataset used in this project contains positive and negative sentiment-labelled sentences. It contains three files of review from Amazon, IMDB and Yelp. The files were combined in a new file named review.csv.\n",
    "\n",
    "CountVectorizer was used to preprocess, tokenize, and filter the stop words in the dataset.  Tf-idf or Term Frequent, Inverse Document Frequency was used to the dataset. The group used tf-idf to have knowledge on the importance of words according to the frequency of their appearance in multiple documents.\n",
    "\n",
    "After the preprocessing, tokenizing and getting the occurences, the dataset was split into training and test set by using the train_test_split function. We used 0.3 for the test_size, and 100 for the random_state.\n",
    "\n",
    "The training set was trained using the MultinomialNB or Multinomial Naive Bayes. Predict function was used to predict the test set. The output of the predict function was also used in computing the accuracy, precision and recall scores.\n",
    "\n",
    "\n",
    "## III.  Data and Analysis\n",
    "\n",
    "The dataset was created in 2015 for the paper “From Group to Individual Labels using Deep Features.” The data has the following features: sentence, score. Sentences are extracted from reviews of products, movies, and restaurants. A sentence is scored 1 for positive and 0 for negative. \n",
    "\n",
    "According to the authors, they selected 50% positive and 50% negative of the 2748 reviews randomly from a larger dataset of reviews. They tried to select reviews that are clearly positive or negative, and avoided neutral sentences.\n",
    "\n",
    "\n",
    "## IV.  Conclusion\n",
    "\n",
    "The model boasts an accuracy score of 81.09%. Positive sentiment classifier has a precision score of 80.19% and a recall score of 82.15%, while the negative sentiment classifier has a precision score of 82.02% and a recall score of 80.05%. \n",
    "\n",
    "\n",
    "## V.  Contribution\n",
    "\n",
    "\tAbenojar, Jesrelle Anne\n",
    "        - Finding dataset\n",
    "        - Model training\n",
    "        - Documentation\n",
    "\n",
    "\tAlvaro, Justine Paul\n",
    "        - Finding model\n",
    "        - Model training\n",
    "        - Documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "- https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "- https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn\n",
    "- https://searchengineland.com/88-consumers-trust-online-reviews-much-personal-recommendations-195803 \n",
    "- https://stevenloria.com/tf-idf/\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing, tokenizing and getting the occurrences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-04d6aa05a3f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'review'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "counts = vect.fit_transform(data['review']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf_transform = tfidf.fit_transform(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_transform, data['class'], test_size=0.3, random_state=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 0.8109\n",
      "\n",
      "Precision Scores for Positive, Negative:\n",
      ">> 0.8019\n",
      ">> 0.8202\n",
      "\n",
      "Recall Scores for Positive, Negative:\n",
      ">> 0.8215\n",
      ">> 0.8005\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy Score: {0:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('\\nPrecision Scores for Positive, Negative:')\n",
    "for i in precision_score(y_test, y_pred, average=None):\n",
    "    print('>> {0:.4f}'.format(i))\n",
    "print('\\nRecall Scores for Positive, Negative:')\n",
    "for i in recall_score(y_test, y_pred,average=None):\n",
    "    print('>> {0:.4f}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[336  73]\n",
      " [ 83 333]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a review: The food tastes awesome\n",
      "Positive sentiment\n"
     ]
    }
   ],
   "source": [
    "sentence = []\n",
    "s = input(\"Enter a review: \")\n",
    "sentence.append(s)\n",
    "\n",
    "sentence_counts = vect.transform(sentence)\n",
    "sentence_tfidf = tfidf.transform(sentence_counts)\n",
    "\n",
    "sentiment = mnb.predict(sentence_tfidf)\n",
    "\n",
    "sentiment[0]\n",
    "if sentiment[0] == 0:\n",
    "    print(\"Negative sentiment\")\n",
    "else: \n",
    "    print(\"Positive sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
